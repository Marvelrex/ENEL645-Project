{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f8818f5-fc7a-480e-8919-904f5ca7461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from pytorch_pretrained_biggan import BigGAN, one_hot_from_names, truncated_noise_sample\n",
    "from pytorch_fid.fid_score import calculate_fid_given_paths\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision import transforms\n",
    "from scipy.stats import entropy\n",
    "from scipy.linalg import sqrtm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from min_dalle import MinDalle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495fc751-1a74-40f9-8939-0992fc29cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save images\n",
    "output_dir = \"./images\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create the directory if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fda6196-7157-4b9e-8873-617b9db7beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Stable Diffusion...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0e9d466207462097c12831124a906a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a2c27c015645688c862b0592ba2ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_A_large_airliner_jet_flying_through_the_blue_sky.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52199fe4b950499dbf4c125a6ee149e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_A_husky_is_lying_under_an_elephant_toy.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697c9fecfdfb4c3d9ebd2e6041bbd534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f4f6e800c0454da775bbb8eed7f57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_Three_zebras_and_other_wild_animals_out_in_a_semi-green_field.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322d5c34a6e04e8ca00cadfcd9ea4671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b16ee4c7397497a81286dff0c76b248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_A_close_up_of_dozens_of_oranges_stacked.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22492573e53c4050b6dc6db2a9193274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_airliner.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49033d237bb47daa389c3d4c613a509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stable Diffusion - Saved: ./images\\stable_diffusion\\stable_diffusion_husky.png\n"
     ]
    }
   ],
   "source": [
    "### Stable Diffusion\n",
    "# Load the pre-trained Stable Diffusion pipeline\n",
    "print(\"Loading Stable Diffusion...\")\n",
    "stable_pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(\"cuda\")\n",
    "\n",
    "# Stable Diffusion prompts\n",
    "stable_prompts = [\n",
    "    \"A large airliner jet flying through the blue sky.\",\n",
    "    \"A husky is lying under an elephant toy.\",\n",
    "    \"A lady dressed in a blue and purple outfit wearing a hat made of fruit.\",\n",
    "    \"Three zebras and other wild animals out in a semi-green field.\",\n",
    "    \"Woman enjoying down hill skiing at a well-groomed resort.\",\n",
    "    \"A close up of dozens of oranges stacked.\",\n",
    "    \"airliner\",\n",
    "    \"husky\"\n",
    "]\n",
    "stable_output_dir = os.path.join(output_dir, \"stable_diffusion\")\n",
    "os.makedirs(stable_output_dir, exist_ok=True)\n",
    "# Generate and save Stable Diffusion images\n",
    "for idx, prompt in enumerate(stable_prompts):\n",
    "    image = stable_pipe(prompt).images[0]\n",
    "    filename = os.path.join(stable_output_dir, f\"stable_diffusion_{prompt.replace(' ', '_').replace('.', '')}.png\")\n",
    "    image.save(filename)\n",
    "    print(f\"Stable Diffusion - Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d2e17e-b5d9-4116-bd54-bb62a4e139cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BigGAN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hjhjjhg\\AppData\\Roaming\\Python\\Python312\\site-packages\\pytorch_pretrained_biggan\\model.py:279: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(resolved_model_file, map_location='cpu' if not torch.cuda.is_available() else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Labels: ['airliner']\n",
      "Description: A large airliner jet flying through the blue sky.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_A_large_airliner_jet_flying_through_the_blue_sky.png\n",
      "Processing Labels: ['husky', 'elephant']\n",
      "Description: A husky is lying under an elephant toy.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_A_husky_is_lying_under_an_elephant_toy.png\n",
      "Processing Labels: ['cowboy hat', 'banana']\n",
      "Description: A lady dressed in a blue and purple outfit wearing a hat made of fruit.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit.png\n",
      "Processing Labels: ['zebra']\n",
      "Description: Three zebras and other wild animals out in a semi-green field.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_Three_zebras_and_other_wild_animals_out_in_a_semi-green_field.png\n",
      "Processing Labels: ['ski']\n",
      "Description: Woman enjoying down hill skiing at a well-groomed resort.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort.png\n",
      "Processing Labels: ['husky']\n",
      "Description: husky\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_husky.png\n",
      "Processing Labels: ['airliner']\n",
      "Description: airliner\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_airliner.png\n",
      "Processing Labels: ['orange']\n",
      "Description: A close up of dozens of oranges stacked.\n",
      "BigGAN - Saved blended image: ./images\\big_GAN\\big_GAN_A_close_up_of_dozens_of_oranges_stacked.png\n"
     ]
    }
   ],
   "source": [
    "### BigGAN\n",
    "# Load the pre-trained BigGAN model\n",
    "print(\"Loading BigGAN...\")\n",
    "biggan_model = BigGAN.from_pretrained('biggan-deep-256')\n",
    "biggan_model.eval()\n",
    "biggan_output_dir = os.path.join(output_dir, \"big_GAN\")\n",
    "os.makedirs(biggan_output_dir, exist_ok=True)\n",
    "# BigGAN prompts\n",
    "prompts_list = [\n",
    "    ([\"airliner\"], \"A large airliner jet flying through the blue sky.\"),\n",
    "    ([\"husky\", \"elephant\"], \"A husky is lying under an elephant toy.\"),\n",
    "    ([\"cowboy hat\", \"banana\"], \"A lady dressed in a blue and purple outfit wearing a hat made of fruit.\"),\n",
    "    ([\"zebra\"], \"Three zebras and other wild animals out in a semi-green field.\"),\n",
    "    ([\"ski\"], \"Woman enjoying down hill skiing at a well-groomed resort.\"),\n",
    "    ([\"husky\"], \"husky\"),\n",
    "    ([\"airliner\"], \"airliner\"),\n",
    "    ([\"orange\"], \"A close up of dozens of oranges stacked.\")\n",
    "]\n",
    "#Generate a BigGAN image and save it with a filename based on the descriptive prompt\n",
    "def generate_biggan_image_with_labels_auto_weights(model, output_dir, prompts, descriptive_prompt, weights=None):\n",
    "    # Check that at least one prompt is provided\n",
    "    assert len(prompts) > 0, \"At least one prompt must be provided.\"\n",
    "\n",
    "    # Assign equal weights if none are provided\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(prompts)] * len(prompts)\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    total_weight = sum(weights)\n",
    "    weights = [w / total_weight for w in weights]\n",
    "\n",
    "    # Generate class vector\n",
    "    class_vectors = [one_hot_from_names([prompt], batch_size=1) for prompt in prompts]\n",
    "    class_vectors = [torch.from_numpy(cv).float() for cv in class_vectors if cv is not None]\n",
    "\n",
    "    if not class_vectors:\n",
    "        print(f\"BigGAN - Invalid prompts: {prompts}. Ensure they are valid ImageNet classes.\")\n",
    "        return\n",
    "\n",
    "    # Blend class vectors using the normalized weights\n",
    "    blended_class_vector = sum(w * cv for w, cv in zip(weights, class_vectors))\n",
    "\n",
    "    # Generate noise vector\n",
    "    noise_vector = truncated_noise_sample(truncation=0.4, batch_size=1)\n",
    "    noise_vector = torch.from_numpy(noise_vector).float()\n",
    "\n",
    "    # Generate the image\n",
    "    with torch.no_grad():\n",
    "        output = model(noise_vector, blended_class_vector, truncation=0.4)\n",
    "\n",
    "    output = (output.clamp(min=-1, max=1) + 1) / 2.0  # Rescale to [0, 1]\n",
    "\n",
    "    # Prepare a filename based on the descriptive prompt\n",
    "    sanitized_prompt = descriptive_prompt.replace(\" \", \"_\").replace(\".\", \"\")  # Replace spaces and remove dots\n",
    "    filename = os.path.join(output_dir, f\"big_GAN_{sanitized_prompt}.png\")\n",
    "\n",
    "    # Save the image\n",
    "    save_image(output, filename)\n",
    "    print(f\"BigGAN - Saved blended image: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "# Process the prompts list and generate images\n",
    "def process_prompts(prompts_list):\n",
    "    for labels, description in prompts_list:\n",
    "        # `labels` is a list of class labels\n",
    "        print(f\"Processing Labels: {labels}\")\n",
    "        print(f\"Description: {description}\")\n",
    "\n",
    "        # Generate BigGAN images\n",
    "        generate_biggan_image_with_labels_auto_weights(\n",
    "            model=biggan_model,\n",
    "            output_dir=biggan_output_dir,\n",
    "            prompts=labels,  # Use labels directly as a list\n",
    "            descriptive_prompt=description\n",
    "        )\n",
    "\n",
    "\n",
    "# Execute the processing\n",
    "process_prompts(prompts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13be9740-383c-43a4-b26a-1b2c70a3d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MinDalle...\n",
      "using device cuda\n",
      "intializing TextTokenizer\n",
      "initializing DalleBartEncoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  params = torch.load(self.encoder_params_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing DalleBartDecoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  params = torch.load(self.decoder_params_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing VQGanDetokenizer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:151: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  params = torch.load(self.detoker_params_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating image for prompt: A large airliner jet flying through the blue sky.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:201: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=self.dtype):\n",
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:208: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=self.dtype):\n",
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:239: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=self.dtype):\n",
      "C:\\ProgramData\\anaconda3\\envs\\my-env\\Lib\\site-packages\\min_dalle\\min_dalle.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float32):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_A_large_airliner_jet_flying_through_the_blue_sky.png\n",
      "Generating image for prompt: A husky is lying under an elephant toy.\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_A_husky_is_lying_under_an_elephant_toy.png\n",
      "Generating image for prompt: A lady dressed in a blue and purple outfit wearing a hat made of fruit.\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit.png\n",
      "Generating image for prompt: Three zebras and other wild animals out in a semi-green field.\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_Three_zebras_and_other_wild_animals_out_in_a_semi-green_field.png\n",
      "Generating image for prompt: Woman enjoying down hill skiing at a well-groomed resort.\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort.png\n",
      "Generating image for prompt: A close up of dozens of oranges stacked.\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_A_close_up_of_dozens_of_oranges_stacked.png\n",
      "Generating image for prompt: airliner\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_airliner.png\n",
      "Generating image for prompt: husky\n",
      "MinDalle - Saved: ./images\\min_DALL-E\\min_DALL-E_husky.png\n"
     ]
    }
   ],
   "source": [
    "### MinDalle\n",
    "# Initialize MinDalle model\n",
    "print(\"Loading MinDalle...\")\n",
    "min_dalle_model = MinDalle(\n",
    "    models_root='./pretrained',\n",
    "    dtype=torch.float32,\n",
    "    device='cuda',\n",
    "    is_mega=True,\n",
    "    is_reusable=True\n",
    ")\n",
    "dalle_output_dir = os.path.join(output_dir, \"min_DALL-E\")\n",
    "os.makedirs(dalle_output_dir, exist_ok=True)\n",
    "# MinDalle prompts\n",
    "min_dalle_prompts = [\n",
    "    \"A large airliner jet flying through the blue sky.\",\n",
    "    \"A husky is lying under an elephant toy.\",\n",
    "    \"A lady dressed in a blue and purple outfit wearing a hat made of fruit.\",\n",
    "    \"Three zebras and other wild animals out in a semi-green field.\",\n",
    "    \"Woman enjoying down hill skiing at a well-groomed resort.\",\n",
    "    \"A close up of dozens of oranges stacked.\",\n",
    "    \"airliner\",\n",
    "    \"husky\"\n",
    "]\n",
    "\n",
    "# Generate and save MinDalle images\n",
    "for prompt in min_dalle_prompts:\n",
    "    print(f\"Generating image for prompt: {prompt}\")\n",
    "    image = min_dalle_model.generate_image(\n",
    "        text=prompt,\n",
    "        seed=-1,\n",
    "        grid_size=1,\n",
    "        is_seamless=False,\n",
    "        temperature=1.0,\n",
    "        top_k=256,\n",
    "        supercondition_factor=32,\n",
    "        is_verbose=False\n",
    "    )\n",
    "    filename = os.path.join(dalle_output_dir, f\"min_DALL-E_{prompt.replace(' ', '_').replace('.', '')}.png\")\n",
    "    image.save(filename)\n",
    "    print(f\"MinDalle - Saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3eeec69-2d5d-4324-937a-c372140bea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deine paths and models\n",
    "generated_images_folder = \"./images\"\n",
    "real_images_folder = \"./real_images\"\n",
    "models = [\"big_GAN\", \"min_DALL-E\", \"stable_diffusion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a24f93-0cf6-431a-b4c8-b8ec5d2d72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary folders for FID calculations\n",
    "TEMP_REAL_FOLDER = \"./temp_real\"\n",
    "TEMP_GENERATED_FOLDER = \"./temp_generated\"\n",
    "\n",
    "# Ensure temporary folders exist\n",
    "os.makedirs(TEMP_REAL_FOLDER, exist_ok=True)\n",
    "os.makedirs(TEMP_GENERATED_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "def calculate_fid_for_prompt(prompt, generated_folder, real_folder, models, device=\"cuda\"):\n",
    "    fid_scores = []\n",
    "\n",
    "    # Save real image to the temporary real folder\n",
    "    real_image_path = os.path.join(real_folder, f\"{prompt}.jpg\")\n",
    "    if os.path.exists(real_image_path):\n",
    "        real_image = Image.open(real_image_path)\n",
    "        real_image.save(os.path.join(TEMP_REAL_FOLDER, f\"{prompt}.jpg\"))\n",
    "    else:\n",
    "        print(f\"Real image for prompt '{prompt}' is missing.\")\n",
    "        return []\n",
    "\n",
    "    # Calculate FID for each model\n",
    "    for model_name in models:\n",
    "        generated_image_path = os.path.join(generated_folder, model_name, f\"{model_name}_{prompt}.png\")\n",
    "        if not os.path.exists(generated_image_path):\n",
    "            generated_image_path = os.path.join(generated_folder, model_name, f\"{model_name}_{prompt}.jpg\")\n",
    "        \n",
    "        if os.path.exists(generated_image_path):\n",
    "            generated_image = Image.open(generated_image_path)\n",
    "            generated_image.save(os.path.join(TEMP_GENERATED_FOLDER, f\"{model_name}_{prompt}.png\"))\n",
    "\n",
    "            # Calculate FID\n",
    "            fid_score = calculate_fid_given_paths(\n",
    "                [TEMP_REAL_FOLDER, TEMP_GENERATED_FOLDER],\n",
    "                batch_size=10,\n",
    "                device=device,\n",
    "                dims=2048\n",
    "            )\n",
    "            fid_scores.append((model_name, fid_score))\n",
    "\n",
    "            # Clean up temporary generated folder\n",
    "            os.remove(os.path.join(TEMP_GENERATED_FOLDER, f\"{model_name}_{prompt}.png\"))\n",
    "        else:\n",
    "            print(f\"Generated image for model '{model_name}' and prompt '{prompt}' is missing.\")\n",
    "\n",
    "    # Clean up temporary real folder\n",
    "    os.remove(os.path.join(TEMP_REAL_FOLDER, f\"{prompt}.jpg\"))\n",
    "    return fid_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a119a2-5d66-4426-940e-96973f6facbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_images_and_fid(prompt, generated_folder, real_folder, output_folder, fid_scores, models):\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Prepare figure: one real image + one for each model\n",
    "    num_images = len(models) + 1  # +1 for the real image\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(6 * num_images, 6))  # Dynamic layout\n",
    "\n",
    "    # Load the real image\n",
    "    real_image_path = os.path.join(real_folder, f\"{prompt}.jpg\")\n",
    "    if os.path.exists(real_image_path):\n",
    "        real_image = Image.open(real_image_path)\n",
    "        axes[0].imshow(real_image)\n",
    "        axes[0].set_title(\"Real Image\", fontsize=12, pad=10)  # Added padding\n",
    "        axes[0].axis('off')\n",
    "    else:\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(\"Real Image (Missing)\", fontsize=12, pad=10)  # Added padding\n",
    "\n",
    "    # Add generated images with FID scores\n",
    "    for idx, model_name in enumerate(models):\n",
    "        generated_image_path = os.path.join(generated_folder, model_name, f\"{model_name}_{prompt}.png\")\n",
    "        if not os.path.exists(generated_image_path):\n",
    "            generated_image_path = os.path.join(generated_folder, model_name, f\"{model_name}_{prompt}.jpg\")\n",
    "        \n",
    "        if os.path.exists(generated_image_path):\n",
    "            generated_image = Image.open(generated_image_path)\n",
    "            axes[idx + 1].imshow(generated_image)\n",
    "\n",
    "            # Find corresponding FID score\n",
    "            fid_score = next((score for name, score in fid_scores if name == model_name), None)\n",
    "            if fid_score is not None:\n",
    "                axes[idx + 1].set_title(f\"{model_name}\\nFID: {fid_score:.2f}\", fontsize=10, pad=10)  # Added padding\n",
    "            else:\n",
    "                axes[idx + 1].set_title(model_name, fontsize=10, pad=10)  # Added padding\n",
    "        else:\n",
    "            axes[idx + 1].axis('off')\n",
    "            axes[idx + 1].set_title(f\"{model_name} (Missing)\", fontsize=12, pad=10)  # Added padding\n",
    "        axes[idx + 1].axis('off')\n",
    "\n",
    "    # Adjust layout to ensure titles are fully visible\n",
    "    plt.subplots_adjust(top=0.85)  # Increase space at the top of the figure\n",
    "    # Save the plot\n",
    "    output_file_path = os.path.join(output_folder, f\"combined_FID_{prompt}.png\")\n",
    "    plt.savefig(output_file_path, dpi=300, bbox_inches=\"tight\")  # Use bbox_inches=\"tight\" to include all elements\n",
    "    plt.close()\n",
    "    print(f\"Combined plot saved to: {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa9b72d-c8da-43da-9044-0337222b9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_fid(avg_fid, output_folder):\n",
    "    \"\"\"\n",
    "    Plot average FID scores for each model with values displayed on bars.\n",
    "\n",
    "    Args:\n",
    "    - avg_fid: Dictionary with model names as keys and their average FID scores.\n",
    "    - output_folder: Path to save the plot.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    models = list(avg_fid.keys())\n",
    "    avg_fid_scores = list(avg_fid.values())\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(models, avg_fid_scores, color='green')\n",
    "    plt.title(\"Average FID Scores per Model\")\n",
    "    plt.ylabel(\"Average FID Score\")\n",
    "    plt.xlabel(\"Model\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Add text on bars\n",
    "    for bar, score in zip(bars, avg_fid_scores):\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,\n",
    "            bar.get_height() + 1,  # Position the text slightly above the bar\n",
    "            f\"{score:.2f}\",  # Format the score with 2 decimal places\n",
    "            ha='center', va='bottom', fontsize=10\n",
    "        )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_folder, \"Average_FID_per_model.png\")\n",
    "    plt.savefig(output_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved average FID plot to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861ca5b2-4169-4507-9adc-e41f13050fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_prompts(prompts, generated_folder, real_folder, output_folder, models, device=\"cuda\"):\n",
    "    # Store average FID scores\n",
    "    average_fid_scores = {model: [] for model in models}\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(f\"Processing prompt: {prompt}\")\n",
    "\n",
    "        # Calculate FID scores\n",
    "        fid_scores = calculate_fid_for_prompt(prompt, generated_folder, real_folder, models, device=device)\n",
    "\n",
    "        # Add scores to averages\n",
    "        for model_name, fid_score in fid_scores:\n",
    "            average_fid_scores[model_name].append(fid_score)\n",
    "\n",
    "        # Generate combined plot for this prompt\n",
    "        plot_combined_images_and_fid(prompt, generated_folder, real_folder, output_folder, fid_scores, models)\n",
    "\n",
    "    # Calculate and plot average FID scores\n",
    "    avg_fid = {model: sum(scores) / len(scores) for model, scores in average_fid_scores.items() if scores}\n",
    "    plot_average_fid(avg_fid, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92c7015f-e95c-4afa-9663-d9e2b8bb83f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing prompt: A_large_airliner_jet_flying_through_the_blue_sky\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_A_large_airliner_jet_flying_through_the_blue_sky.png\n",
      "Processing prompt: A_husky_is_lying_under_an_elephant_toy\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_A_husky_is_lying_under_an_elephant_toy.png\n",
      "Processing prompt: A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit.png\n",
      "Processing prompt: Three_zebras_and_other_wild_animals_out_in_a_semi-green_field\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_Three_zebras_and_other_wild_animals_out_in_a_semi-green_field.png\n",
      "Processing prompt: Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort.png\n",
      "Processing prompt: A_close_up_of_dozens_of_oranges_stacked\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_A_close_up_of_dozens_of_oranges_stacked.png\n",
      "Processing prompt: airliner\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_airliner.png\n",
      "Processing prompt: husky\n",
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: batch size is bigger than the data size. Setting batch size to data size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined plot saved to: ./output_combined\\combined_FID_husky.png\n",
      "Saved average FID plot to: ./output_combined\\Average_FID_per_model.png\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "prompts = [\n",
    "    \"A_large_airliner_jet_flying_through_the_blue_sky\",\n",
    "    \"A_husky_is_lying_under_an_elephant_toy\",\n",
    "    \"A_lady_dressed_in_a_blue_and_purple_outfit_wearing_a_hat_made_of_fruit\",\n",
    "    \"Three_zebras_and_other_wild_animals_out_in_a_semi-green_field\",\n",
    "    \"Woman_enjoying_down_hill_skiing_at_a_well-groomed_resort\",\n",
    "    \"A_close_up_of_dozens_of_oranges_stacked\",\n",
    "    \"airliner\",\n",
    "    \"husky\"\n",
    "]\n",
    "\n",
    "output_folder = \"./output_combined\"\n",
    "\n",
    "process_all_prompts(prompts, generated_images_folder, real_images_folder, output_folder, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
